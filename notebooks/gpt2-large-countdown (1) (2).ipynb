{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6814ab0-b5c6-4bb4-9a35-2fe88c2585d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  7 20:24:04 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A4000               On  |   00000000:01:00.0 Off |                  Off |\n",
      "| 41%   39C    P8             15W /  140W |       2MiB /  16376MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac8cb65-e041-4c92-84d1-d19a74537d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Set memory allocation to be more efficient\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616aa6ab-25e7-48ef-bd22-7ee6374d962a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                            Size  Used Avail Use% Mounted on\n",
      "overlay                                16G  7.0G  9.1G  44% /\n",
      "tmpfs                                  64M     0   64M   0% /dev\n",
      "shm                                    15G     0   15G   0% /dev/shm\n",
      "/dev/nvme0n1p1                        3.7T  913G  2.8T  25% /etc/hosts\n",
      "/dev/mapper/ubuntu--vg--1-ubuntu--lv  1.8T   35G  1.7T   3% /usr/bin/nvidia-smi\n",
      "tmpfs                                  63G     0   63G   0% /sys/fs/cgroup\n",
      "tmpfs                                  63G   12K   63G   1% /proc/driver/nvidia\n",
      "tmpfs                                  63G  4.0K   63G   1% /etc/nvidia/nvidia-application-profiles-rc.d\n",
      "tmpfs                                  13G   14M   13G   1% /run/nvidia-persistenced/socket\n",
      "tmpfs                                  63G     0   63G   0% /proc/asound\n",
      "tmpfs                                  63G     0   63G   0% /proc/acpi\n",
      "tmpfs                                  63G     0   63G   0% /proc/scsi\n",
      "tmpfs                                  63G     0   63G   0% /sys/firmware\n",
      "tmpfs                                  63G     0   63G   0% /sys/devices/virtual/powercap\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d4d072f-e573-4634-88a1-f2e1d29283b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11G\t/usr\n",
      "7.5G\t/venv\n",
      "5.2G\t/root\n",
      "1.8G\t/opt\n",
      "112M\t/var\n",
      "28M\t/train.jsonl\n",
      "3.9M\t/wandb\n",
      "2.8M\t/validation.jsonl\n",
      "2.3M\t/etc\n",
      "1.1M\t/test_ood_1e5.jsonl\n"
     ]
    }
   ],
   "source": [
    "!du -hs /* 2>/dev/null | sort -rh | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27e78b2-848b-4267-ae86-cd8ca5763e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "du: cannot read directory 'proc/84/task/84/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/84/map_files': Permission denied\n",
      "du: cannot read directory 'proc/84/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/115/task/115/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/115/map_files': Permission denied\n",
      "du: cannot read directory 'proc/115/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/116/task/116/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/116/map_files': Permission denied\n",
      "du: cannot read directory 'proc/116/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/134/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/136/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/137/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/138/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/139/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/140/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/142/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/143/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/144/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/145/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/146/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/task/147/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/134/map_files': Permission denied\n",
      "du: cannot read directory 'proc/134/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/149/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/150/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/151/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/152/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/153/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/154/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/155/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/156/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/157/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/158/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/159/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/164/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/166/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/167/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/168/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/task/276/fdinfo': Permission denied\n",
      "du: cannot read directory 'proc/149/map_files': Permission denied\n",
      "du: cannot read directory 'proc/149/fdinfo': Permission denied\n",
      "du: cannot access 'proc/595/task/595/fd/4': No such file or directory\n",
      "du: cannot access 'proc/595/task/595/fdinfo/4': No such file or directory\n",
      "du: cannot access 'proc/595/fd/3': No such file or directory\n",
      "du: cannot access 'proc/595/fdinfo/3': No such file or directory\n",
      "0\tbin\n",
      "0\tboot\n",
      "0\tdata\n",
      "0\tdev\n",
      "0\tgpt2-large-countdown\n",
      "0\tlib\n",
      "0\tlib32\n",
      "0\tlib64\n",
      "0\tlibx32\n",
      "0\tmedia\n",
      "0\tmnt\n",
      "0\tsbin\n",
      "0\tsrv\n",
      "0\tsys\n",
      "8.0K\t=0.26.0\n",
      "8.0K\tcuda-keyring_1.0-1_all.deb\n",
      "12K\tproc\n",
      "20K\tNGC-DL-CONTAINER-LICENSE\n",
      "20K\trun\n",
      "80K\tgpt2-large-countdown (1).ipynb\n",
      "84K\thome\n",
      "188K\tworkspace\n",
      "444K\ttmp\n",
      "976K\ttest_ood_1e3.jsonl\n",
      "1020K\ttest_ood_1e4.jsonl\n",
      "1.1M\ttest_ood_1e5.jsonl\n",
      "2.3M\tetc\n",
      "2.8M\tvalidation.jsonl\n",
      "3.9M\twandb\n",
      "28M\ttrain.jsonl\n",
      "113M\tvar\n",
      "805M\troot\n",
      "1.8G\topt\n",
      "7.5G\tvenv\n",
      "11G\tusr\n"
     ]
    }
   ],
   "source": [
    "!du -sh * | sort -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f1b5e4f-ea0a-4e65-97e5-de93e0b2d09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t/usr/games\n",
      "0\t/usr/lib64\n",
      "0\t/usr/libx32\n",
      "4.0K\t/usr/etc\n",
      "92K\t/usr/src\n",
      "1.6M\t/usr/libexec\n",
      "9.4M\t/usr/sbin\n",
      "15M\t/usr/lib32\n",
      "27M\t/usr/include\n",
      "174M\t/usr/bin\n",
      "326M\t/usr/share\n",
      "4.6G\t/usr/local\n",
      "5.9G\t/usr/lib\n"
     ]
    }
   ],
   "source": [
    "!du -sh /usr/* | sort -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5acbb542-6907-46ce-81f7-78fe119e795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Clear Hugging Face cache\n",
    "!rm -rf ~/.cache/huggingface/hub\n",
    "\n",
    "# Or selectively remove specific model caches\n",
    "!rm -rf ~/.cache/huggingface/hub/models--openai-community--gpt2-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3708f60-aa1c-466c-bce6-3d9ab3133e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 13\n"
     ]
    }
   ],
   "source": [
    "!pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b71dc95-7161-4ded-9b44-473419d4b47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tee: /proc/sys/vm/drop_caches: Read-only file system\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "!sync && echo 3 | sudo tee /proc/sys/vm/drop_caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94d360d0-36f4-416a-9988-355d7a4cb315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.51.0\n",
      "Uninstalling transformers-4.51.0:\n",
      "  Successfully uninstalled transformers-4.51.0\n",
      "Found existing installation: torch 2.5.1+cu121\n",
      "Uninstalling torch-2.5.1+cu121:\n",
      "  Successfully uninstalled torch-2.5.1+cu121\n",
      "Found existing installation: torchvision 0.20.1+cu121\n",
      "Uninstalling torchvision-0.20.1+cu121:\n",
      "  Successfully uninstalled torchvision-0.20.1+cu121\n",
      "Found existing installation: torchaudio 2.5.1+cu121\n",
      "Uninstalling torchaudio-2.5.1+cu121:\n",
      "  Successfully uninstalled torchaudio-2.5.1+cu121\n",
      "Found existing installation: tensorflow 2.19.0\n",
      "Uninstalling tensorflow-2.19.0:\n",
      "  Successfully uninstalled tensorflow-2.19.0\n",
      "Found existing installation: tf_keras 2.19.0\n",
      "Uninstalling tf_keras-2.19.0:\n",
      "  Successfully uninstalled tf_keras-2.19.0\n",
      "Found existing installation: datasets 3.5.0\n",
      "Uninstalling datasets-3.5.0:\n",
      "  Successfully uninstalled datasets-3.5.0\n",
      "Found existing installation: accelerate 1.6.0\n",
      "Uninstalling accelerate-1.6.0:\n",
      "  Successfully uninstalled accelerate-1.6.0\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (780.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /venv/main/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /venv/main/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: triton==3.1.0 in /venv/main/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /venv/main/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.10/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /venv/main/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /venv/main/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /venv/main/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /venv/main/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /venv/main/lib/python3.10/site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /venv/main/lib/python3.10/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.0-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 KB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wandb in /venv/main/lib/python3.10/site-packages (0.19.9)\n",
      "Requirement already satisfied: huggingface_hub in /venv/main/lib/python3.10/site-packages (0.30.1)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 KB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: requests in /venv/main/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /venv/main/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /venv/main/lib/python3.10/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /venv/main/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /venv/main/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /venv/main/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: aiohttp in /venv/main/lib/python3.10/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /venv/main/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in /venv/main/lib/python3.10/site-packages (from datasets) (2024.12.0)\n",
      "Requirement already satisfied: pandas in /venv/main/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /venv/main/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pydantic<3 in /venv/main/lib/python3.10/site-packages (from wandb) (2.11.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /venv/main/lib/python3.10/site-packages (from wandb) (6.1.1)\n",
      "Requirement already satisfied: setproctitle in /venv/main/lib/python3.10/site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /venv/main/lib/python3.10/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /venv/main/lib/python3.10/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: platformdirs in /venv/main/lib/python3.10/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /venv/main/lib/python3.10/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /venv/main/lib/python3.10/site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.10/site-packages (from wandb) (59.6.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /venv/main/lib/python3.10/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: torch>=2.0.0 in /venv/main/lib/python3.10/site-packages (from accelerate) (2.5.1+cu121)\n",
      "Requirement already satisfied: keras>=3.5.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /venv/main/lib/python3.10/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /venv/main/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /venv/main/lib/python3.10/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /venv/main/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /venv/main/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /venv/main/lib/python3.10/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /venv/main/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /venv/main/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (6.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /venv/main/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: optree in /venv/main/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: rich in /venv/main/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in /venv/main/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /venv/main/lib/python3.10/site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /venv/main/lib/python3.10/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /venv/main/lib/python3.10/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /venv/main/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /venv/main/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /venv/main/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: triton==3.1.0 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /venv/main/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /venv/main/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /venv/main/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /venv/main/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /venv/main/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /venv/main/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Installing collected packages: transformers, tensorflow, accelerate, tf-keras, datasets\n",
      "Successfully installed accelerate-1.6.0 datasets-3.5.0 tensorflow-2.19.0 tf-keras-2.19.0 transformers-4.51.0\n",
      "accelerate                   1.6.0\n",
      "datasets                     3.5.0\n",
      "torch                        2.5.1+cu121\n",
      "torchaudio                   2.5.1+cu121\n",
      "torchvision                  0.20.1+cu121\n",
      "transformers                 4.51.0\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version used by torch: 12.1\n",
      "Transformers version: 4.51.0\n",
      "Accelerate version: 1.6.0\n"
     ]
    }
   ],
   "source": [
    "# Uninstall potentially conflicting packages for a clean slate\n",
    "!pip uninstall -y transformers torch torchvision torchaudio tensorflow tf-keras datasets accelerate\n",
    "\n",
    "# Install PyTorch with CUDA support (adjust cuXXX if needed for your environment)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install the LATEST stable versions of transformers and other required libraries\n",
    "!pip install transformers datasets wandb huggingface_hub accelerate tensorflow tf-keras\n",
    "\n",
    "# Verify installation\n",
    "!pip list | grep -E 'torch|transformers|datasets|accelerate'\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version used by torch: {torch.version.cuda}\")\n",
    "import transformers\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "import accelerate\n",
    "print(f\"Accelerate version: {accelerate.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "899ce321-f179-46f7-a962-6bd146b3cd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cdbd50e84e4f9b90d351588a8febf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f69a0fa-ed2f-4a80-a946-c6b7beae885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 20:30:46.226623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744057846.245457     432 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744057846.251174     432 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744057846.265966     432 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744057846.265984     432 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744057846.265986     432 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744057846.265988     432 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-07 20:30:46.270676: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgiorogers\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/wandb/run-20250407_203048-u2o99oij</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/giorogers/gpt2-large-countdown/runs/u2o99oij' target=\"_blank\">gpt2-large-countdown-run-1</a></strong> to <a href='https://wandb.ai/giorogers/gpt2-large-countdown' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/giorogers/gpt2-large-countdown' target=\"_blank\">https://wandb.ai/giorogers/gpt2-large-countdown</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/giorogers/gpt2-large-countdown/runs/u2o99oij' target=\"_blank\">https://wandb.ai/giorogers/gpt2-large-countdown/runs/u2o99oij</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/giorogers/gpt2-large-countdown/runs/u2o99oij?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7875a1708a60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(9001)\n",
    "import random\n",
    "random.seed(9001)\n",
    "\n",
    "# Initialize wandb (make sure you are logged in with `wandb login`)\n",
    "wandb.init(project=\"gpt2-large-countdown\", name=\"gpt2-large-countdown-run-1\", reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "614c4797-8301-46db-8b21-1687c7fb8af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "data_files = {\n",
    "    \"train\": \"train.jsonl\",\n",
    "    \"validation\": \"validation.jsonl\",\n",
    "    \"test_1e3\": \"test_ood_1e3.jsonl\"\n",
    "}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "# Combine the fields into a single prompt.\n",
    "def preprocess(example):\n",
    "    \"\"\" Here we combine numbers, target, and the chain-of-thought (CoT) into one string. \"\"\"\n",
    "    cot_text = \" \".join(example[\"cot\"])\n",
    "    text = f\"\"\"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
    "User: Using the numbers {example['numbers']}, create an equation that equals {example['target']}. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\n",
    "Assistant: Let me solve this step by step.\n",
    "<think>{cot_text}</think>\n",
    "<answer>{example['target']}</answer>\"\"\"\n",
    "    return {\"text\": text}\n",
    "\n",
    "# Map the preprocessing function over the dataset splits\n",
    "dataset = dataset.map(preprocess, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd1541b4-2da8-4b70-a724-542fb37d0690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6a0e5cfdde4b8fb77e92c2656415bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c298335ac1a04d1399f6f9e7f676ef5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8084532e95e46bf961d9387f3fd1285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6241069c374fdcb7f3c868496c1591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a62827e28144c9fbbf47e1bae0e84d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the GPT-2 small tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")\n",
    "# GPT-2 doesn't have a pad token by default; we set it equal to the EOS token.\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"numbers\", \"target\", \"cot\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4254639d-7b1f-450b-b07c-172e85312120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator for causal language modeling (no MLM masking needed)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b4f4813-ce82-4120-8bb0-b444350e1f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268be722e08e4df0b93986a2aa694b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de99ed4f86864b62beaad3687f2bfee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0245843fad434e8501333cf4415f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-large-countdown\",\n",
    "    eval_strategy=\"steps\", # Evaluate at set steps instead of at the end of each epoch\n",
    "    eval_steps=500, # Evaluate every 500 steps\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=1,\n",
    "    save_only_model=True,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    push_to_hub=True, # Automatically push checkpoints and final model to the Hub\n",
    "    hub_model_id=\"giordanorogers/gpt2-large-countdown\", # Replace with your repo ID\n",
    "    load_best_model_at_end=True, # Automatically load the best model based on eval_loss\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    report_to=[\"wandb\"]\n",
    ")\n",
    "\n",
    "# Skip the TensorFlow conversion entirely\n",
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    \"openai-community/gpt2-large\",\n",
    "    use_safetensors=True,\n",
    "    device_map=\"auto\"  # Distribute across available devices\n",
    ")\n",
    "# Set the pad_token_id to avoid warnings during training\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0094a096-3387-4f02-b2ae-910a95b88889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='501' max='46875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  501/46875 12:42 < 19:41:24, 0.65 it/s, Epoch 0.05/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.229880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:603] . unexpected pos 533867328 vs 533867220",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/torch/serialization.py:850\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 850\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/torch/serialization.py:1114\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[0;32m-> 1114\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:778] . PytorchStreamWriter failed writing file data/121: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m trainer\u001b[38;5;241m.\u001b[39mpush_to_hub()\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/transformers/trainer.py:2236\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 2236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2237\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2243\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/transformers/trainer.py:2627\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2627\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2638\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/transformers/trainer.py:3103\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3100\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save \u001b[38;5;241m=\u001b[39m is_new_best_metric\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3103\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/transformers/trainer.py:3211\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3207\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbest_model_checkpoint \u001b[38;5;241m=\u001b[39m best_checkpoint_dir\n\u001b[1;32m   3209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   3210\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[0;32m-> 3211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_scaler(output_dir)\n\u001b[1;32m   3213\u001b[0m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/transformers/trainer.py:3339\u001b[0m, in \u001b[0;36mTrainer._save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   3334\u001b[0m     save_fsdp_optimizer(\n\u001b[1;32m   3335\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfsdp_plugin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, output_dir\n\u001b[1;32m   3336\u001b[0m     )\n\u001b[1;32m   3337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   3338\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 3339\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3341\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[1;32m   3342\u001b[0m is_deepspeed_custom_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   3343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[1;32m   3344\u001b[0m )\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/torch/serialization.py:849\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    846\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    850\u001b[0m         _save(\n\u001b[1;32m    851\u001b[0m             obj,\n\u001b[1;32m    852\u001b[0m             opened_zipfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m             _disable_byteorder_record,\n\u001b[1;32m    856\u001b[0m         )\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/torch/serialization.py:690\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:603] . unexpected pos 533867328 vs 533867220"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9298c-df37-4c36-9b06-63487835aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Print tensors in memory\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) and obj.is_cuda:\n",
    "            print(f\"{type(obj).__name__} - Size: {obj.size()} - {obj.dtype} - {obj.device} - {obj.element_size() * obj.nelement() / 1024 / 1024:.2f} MB\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "062e7072-d094-4ab9-a24e-5d06c397b3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37260"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Force garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1b3d8-4b3c-4df9-8809-37dfe4f2acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the OOD test set\n",
    "eval_results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
    "print(\"OOD Test Evaluation:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765d0a6-dc67-4a02-9402-26a22dbe315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load the trained model and tokenizer from the local directory (or replace with your Hub repo ID)\n",
    "model = GPT2LMHeadModel.from_pretrained(\"giordanorogers/gpt2-large-countdown\")  # or \"giordanorogers/gpt2-small-countdown\" if pushed\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Ensure pad_token is set\n",
    "\n",
    "# Create a text generation pipeline\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Define a prompt to test your model\n",
    "numbers = [16, 44, 57, 62, 71, 75]\n",
    "\n",
    "target = 1557\n",
    "\n",
    "prompt = f\"\"\"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
    "User: Using the numbers {numbers}, create an equation that equals {target}. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work in <think> </think> tags. And return the final answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.\n",
    "Assistant: Let me solve this step by step.\n",
    "<think>\"\"\"\n",
    "\n",
    "# Generate output\n",
    "output = generator(prompt, max_length=300, truncation=True, num_return_sequences=1)\n",
    "\n",
    "# Print the generated outputa\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5ad45-3a5d-425c-91b8-ba4eccb3f3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
