{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnsight\n",
    "import transformers\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "input_size = 5\n",
    "hidden_dims = 10\n",
    "output_size = 2\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    OrderedDict(\n",
    "        [\n",
    "            (\"layer1\", torch.nn.Linear(input_size, hidden_dims)),\n",
    "            (\"layer2\", torch.nn.Linear(hidden_dims, output_size)),\n",
    "        ]\n",
    "    )\n",
    ").requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import NNsight\n",
    "\n",
    "tiny_model = NNsight(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (layer1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (layer2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(tiny_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (layer1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (layer2): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enter the tracing context by calling `model.trace(<input>)` on an NNsight model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand((1, input_size))\n",
    "\n",
    "with tiny_model.trace(input) as tracer:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1626, 0.4687]])\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input) as tracer:\n",
    "    output = tiny_model.output.save()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2155,  0.3026, -0.2610, -0.2924,  0.8791, -0.3922,  0.6998, -0.2105,\n",
      "         -0.4250, -0.3945]])\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input) as tracer:\n",
    "    l1_output = tiny_model.layer1.output.save()\n",
    "print(l1_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2155,  0.3026, -0.2610, -0.2924,  0.8791, -0.3922,  0.6998, -0.2105,\n",
      "         -0.4250, -0.3945]])\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input):\n",
    "    l2_input = tiny_model.layer2.input.save()\n",
    "print(l2_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input):\n",
    "    l1_output = tiny_model.layer1.output\n",
    "    l1_amax = torch.argmax(l1_output, dim=1).save()\n",
    "print(l1_amax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3216)\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input):\n",
    "    value = (tiny_model.layer1.output.sum() + tiny_model.layer2.output.sum()).save()\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nnsight.apply()` allows us to add new functions to the intervention graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.3097) tensor(-0.3097)\n"
     ]
    }
   ],
   "source": [
    "# Take a tensor and return the sum of its elements\n",
    "def tensor_sum(tensor):\n",
    "    flat = tensor.flatten()\n",
    "    total = 0\n",
    "    for element in flat:\n",
    "        total += element.item()\n",
    "\n",
    "    return torch.tensor(total)\n",
    "\n",
    "with tiny_model.trace(input) as tracer:\n",
    "    custom_sum = nnsight.apply(tensor_sum, tiny_model.layer1.output).save()\n",
    "    sum = tiny_model.layer1.output.sum()\n",
    "    sum.save()\n",
    "\n",
    "print(custom_sum, sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2155,  0.3026, -0.2610, -0.2924,  0.8791, -0.3922,  0.6998, -0.2105,\n",
      "         -0.4250, -0.3945]])\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "with tiny_model.trace(input) as tracer:\n",
    "    l1_output = tiny_model.layer1.output.save()\n",
    "    l1_entropy = nnsight.apply(entropy, l1_output).save()\n",
    "print(l1_output)\n",
    "print(l1_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: tensor([[-0.2155,  0.3026, -0.2610, -0.2924,  0.8791, -0.3922,  0.6998, -0.2105,\n",
      "         -0.4250, -0.3945]])\n",
      "After tensor([[ 0.0000,  0.3026, -0.2610, -0.2924,  0.8791, -0.3922,  0.6998, -0.2105,\n",
      "         -0.4250, -0.3945]])\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input):\n",
    "    # Save the output before the edit to compare, applying .clone()\n",
    "    # before saving as the setting operation is in place.\n",
    "    l1_output_before = tiny_model.layer1.output.clone().save()\n",
    "\n",
    "    # Access the -th index of the hidden state dimension and set it\n",
    "    # to zero\n",
    "    tiny_model.layer1.output[:, 0] = 0\n",
    "\n",
    "    # Save the output after to see our edit\n",
    "    l1_output_after = tiny_model.layer1.output.save()\n",
    "\n",
    "print(\"Before:\", l1_output_before)\n",
    "print(\"After\", l1_output_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2155,  0.3026, -0.2610, -0.2924,  0.8791, -0.3922,  0.6998, -0.2105,\n",
      "         -0.4250, -0.3945]])\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping\n",
    "with tiny_model.trace(input):\n",
    "    l1_out = tiny_model.layer1.output.save()\n",
    "    tiny_model.layer1.output.stop()\n",
    "\n",
    "# get the output of the first layer and stop tracing\n",
    "print(l1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10]) is even\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input) as tracer:\n",
    "    rand_int = torch.randint(low=-10, high=10, size=(1,))\n",
    "    with tracer.cond(rand_int % 2 == 0):\n",
    "        tracer.log(rand_int, \"is even\")\n",
    "    with tracer.cond(rand_int % 2 == 1):\n",
    "        tracer.log(rand_int, \"is odd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 is positive and even\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input) as tracer:\n",
    "    non_rand_int = 8\n",
    "    with tracer.cond(non_rand_int > 0):\n",
    "        with tracer.cond(non_rand_int % 2 == 0):\n",
    "            tracer.log(non_rand_int, \"is positive and even\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Integer tensor([-10]) is even\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input) as tracer:\n",
    "    rand_int = torch.randint(low=-10, high=10, size=(1,))\n",
    "    if rand_int % 2 == 0:\n",
    "        tracer.log(\"Random Integer\", rand_int, \"is even\")\n",
    "    else:\n",
    "        tracer.log(\"Random Integer\", rand_int, \"is odd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List: [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.session() as session:\n",
    "\n",
    "    li = nnsight.list()\n",
    "    [li.append([num]) for num in range(0, 3)]\n",
    "    li2 = nnsight.list().save()\n",
    "\n",
    "    # You can create nested Iterator contexts\n",
    "    with session.iter(li) as item:\n",
    "        with session.iter(item) as item_2:\n",
    "            li2.append(item_2)\n",
    "\n",
    "print(\"\\nList:\", li2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "0\n",
      "[1]\n",
      "1\n",
      "[2]\n",
      "2\n",
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.session() as session:\n",
    "    li = nnsight.list()\n",
    "    [li.append([num]) for num in range(0, 3)]\n",
    "    li2 = nnsight.list().save()\n",
    "\n",
    "    for item in li:\n",
    "        session.log(item)\n",
    "        for item2 in item:\n",
    "            session.log(item2)\n",
    "            li2.append(item2)\n",
    "\n",
    "print(li2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      "  (generator): Generator(\n",
      "    (streamer): Streamer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "\n",
    "llm = LanguageModel(\"openai-community/gpt2\", device_map=\"auto\")\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: tensor([[[ -27.5993,  -27.1712,  -29.4423,  ...,  -34.4424,  -34.2497,\n",
      "           -27.0451],\n",
      "         [ -72.0859,  -70.8134,  -75.3755,  ...,  -84.4147,  -81.6738,\n",
      "           -72.0996],\n",
      "         [ -85.3450,  -84.3682,  -90.1620,  ...,  -98.0732,  -96.9377,\n",
      "           -86.8543],\n",
      "         ...,\n",
      "         [ -82.0589,  -77.7474,  -83.8439,  ...,  -94.5601,  -90.0955,\n",
      "           -78.5493],\n",
      "         [ -94.8259,  -91.0452,  -97.5826,  ..., -107.2448, -105.5906,\n",
      "           -91.2598],\n",
      "         [ -86.3132,  -81.4123,  -83.1329,  ...,  -98.7171,  -96.0636,\n",
      "           -82.1496]]], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "Next Token Entropy: 1.2061377\n",
      "Argmax: tensor([[   11,    13, 23852,    42, 31288,    45,  3185,    48,    49,  2257,\n",
      "            52, 30133, 34278,    57]], device='mps:0')\n",
      "Token: Z\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_entropy(probs, axis=1):\n",
    "    return entropy(probs, axis=axis)\n",
    "\n",
    "with llm.trace(\"ABCDEFGHIJKLMNOPQRSTUVWXY\"):\n",
    "    # Access the last layer using h[-1] as it's a ModuleList\n",
    "    # Access the first index of .output as that's where the\n",
    "    # hidden states are.\n",
    "    llm.transformer.h[-1].mlp.output[0][:] = 0\n",
    "\n",
    "    # Get the logits\n",
    "    token_ids = llm.lm_head.output.save()\n",
    "\n",
    "    # Convert logits to probabilities using softmax along vocab dimension\n",
    "    probs = F.softmax(token_ids, dim=-1)\n",
    "\n",
    "    # Calculate entropy on the probability distribution of next tokens\n",
    "    pred_entropy = nnsight.apply(calc_entropy, probs.detach().cpu()).save()\n",
    "    pred_token = token_ids.argmax(dim=-1).save()\n",
    "\n",
    "print(\"Token IDs:\", token_ids)\n",
    "print(\"Next Token Entropy:\", pred_entropy[0][-1])\n",
    "print(\"Argmax:\", pred_token)\n",
    "print(\"Token:\", llm.tokenizer.decode(pred_token[0][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call .trace() it's actually creating two different contexts behind the scenes. The first one is the tracing context, the second is the invoker context. The incoker context defines the values of the input and output Proxies.\n",
    "\n",
    "If we call .trace() with some input, the input is passed on to the invoker. As there is only one input, only one invoker context is created.\n",
    "\n",
    "If we call .trace() without an input, then we call tracer.invoke(input1) to manually create the invoker context with an input, input1. We can also repeatedly call tracer.invoke() to create the invoker context for additional inputs. Every subsequent time we call .invoke(), interventions within its context will only refer to the input in that particular invoke statement.\n",
    "\n",
    "When exiting the tracing context, the inputs from all of the invokers will be batched together, and they will be executed in one forward pass. To test this out, let's do the same ablation experiment, but also add a control output for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original token IDs: tensor([[ 198,   12,  417, 8765,  318,  257,  262, 3504, 7372, 6342]],\n",
      "       device='mps:0')\n",
      "Modified token IDs: tensor([[ 262,   12,  417, 8765,   11,  257,  262, 3504,  338, 3576]],\n",
      "       device='mps:0')\n",
      "Original prediction:  Paris\n",
      "Modified prediction:  London\n"
     ]
    }
   ],
   "source": [
    "with llm.trace() as tracer:\n",
    "    with tracer.invoke(\"The Eiffel Tower is in the city of\"):\n",
    "        # Ablate the last MLP for only this batch\n",
    "        llm.transformer.h[-1].mlp.output[0][:] = 0\n",
    "        # Get the output for only the intervened on batch\n",
    "        token_ids_intervention = llm.lm_head.output.argmax(dim=-1).save()\n",
    "    with tracer.invoke(\"The Eiffel Tower is in the city of\"):\n",
    "        # Get the output for only the original batch\n",
    "        token_ids_original = llm.lm_head.output.argmax(dim=-1).save()\n",
    "print(\"Original token IDs:\", token_ids_original)\n",
    "print(\"Modified token IDs:\", token_ids_intervention)\n",
    "print(\"Original prediction:\", llm.tokenizer.decode(token_ids_original[0][-1]))\n",
    "print(\"Modified prediction:\", llm.tokenizer.decode(token_ids_intervention[0][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with llm.generate('The Eiffel Tower is in the city of', max_new_tokens=3) as tracer:\n",
    "    hidden_states1 = llm.transformer.h[-1].output[0].save()\n",
    "    # use module.next() to access the next intervention\n",
    "    hidden_states2 = llm.transformer.h[-1].next().output[0].save()\n",
    "    # saving the output allows you to save the hidden state across the initial prompt\n",
    "    out = llm.generator.output.save()\n",
    "print(hidden_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
