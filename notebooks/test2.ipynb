{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import math\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom stopping criteria: stop when the last token is a period.\n",
    "class StopOnToken(StoppingCriteria):\n",
    "    def __init__(self, token_id):\n",
    "        self.token_id = token_id\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        # Stop if the last token equals the target token.\n",
    "        if input_ids[0, -1].item() == self.token_id:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer (e.g., GPT-2).\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the stop token (a period).\n",
    "stop_token_id = tokenizer.convert_tokens_to_ids(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(prompt, max_new_tokens=50):\n",
    "    \"\"\"Generate a sentence from a prompt and compute average entropy over generated tokens.\"\"\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    stopping_criteria = StoppingCriteriaList([StopOnToken(stop_token_id)])\n",
    "    \n",
    "    # Use sampling to get diverse outputs.\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_length=input_ids.shape[1] + max_new_tokens,\n",
    "        stopping_criteria=stopping_criteria,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    \n",
    "    generated_ids = outputs.sequences[0]\n",
    "    scores = outputs.scores  # List of tensors (one per generated token)\n",
    "    \n",
    "    # Calculate entropy at each generation step.\n",
    "    entropies = []\n",
    "    epsilon = 1e-10  # Avoid log(0)\n",
    "    for step_logits in scores:\n",
    "        probs = torch.softmax(step_logits, dim=-1)\n",
    "        entropy = -(probs * torch.log(probs + epsilon)).sum()\n",
    "        entropies.append(entropy.item())\n",
    "    \n",
    "    avg_entropy = sum(entropies) / len(entropies) if entropies else 0\n",
    "    sentence = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    return sentence, avg_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple tree node to hold each branch\n",
    "class Branch:\n",
    "    def __init__(self, text, avg_entropy, children=None):\n",
    "        self.text = text\n",
    "        self.avg_entropy = avg_entropy\n",
    "        self.children = children if children is not None else []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Branch(text={self.text!r}, avg_entropy={self.avg_entropy:.2f}, children={self.children})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(prompt, entropy_threshold, num_branches=3, depth=0, max_depth=3):\n",
    "    \"\"\"\n",
    "    Generate a sentence branch and, if the average antropy is above the threshold,\n",
    "    create multiple continuation branches recursively. \n",
    "    \"\"\"\n",
    "    sentence, avg_entropy = generate_sentence(prompt)\n",
    "    branch = Branch(text=sentence, avg_entropy=avg_entropy)\n",
    "\n",
    "    # Continue branching if the sentence is 'uncertain' (entropy above threshold)\n",
    "    # and we haven't reached the maximum tree depth.\n",
    "    if avg_entropy > entropy_threshold and depth < max_depth:\n",
    "        for _ in range(num_branches):\n",
    "            child_branch = build_tree(sentence, entropy_threshold, num_branches, depth+1, max_depth)\n",
    "            branch.children.append(child_branch)\n",
    "    return branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch(text='Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May? Only about a dozen.', avg_entropy=2.78, children=[])\n"
     ]
    }
   ],
   "source": [
    "init_prompt = \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"\n",
    "entropy_threshold = 5.0\n",
    "tree = build_tree(init_prompt, entropy_threshold)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
