{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the effectiveness of chain-of-thought on out-of-distribution (OOD) generalization.\n",
    "\n",
    "We have both empirical and theoretical evidence that chain-of-thought improves LLM performance on certain tasks.\n",
    "And anecdotally openai o1 is clearly better than gpt-4o for most tasks we consider to require some level of complex\n",
    "reasoning.\n",
    "\n",
    "The goal of this experiment is to measure the effectiveness of chain-of-thought itself for OOD generalization. \n",
    "We do this by fine-tuning GPT-2 to solve the countdown game via chain-of-thought.\n",
    "Then we compare its performance to a baseline GPT-2.\n",
    "And for both we test their performance when we make the numbers much larger, effectively pushing the model to\n",
    "generalize what it's learned during training to similar but novel and more complex problems.\n",
    "\n",
    "The hope is that we can learn something about the nature of chain-of-thought as a tool for OOD generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Set the random seed\n",
    "random.seed(9001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start generating our countdown game data, let's clarify some terms:\n",
    "\n",
    "**Generalization:** This is the ability to take our learned inductive biases and use them to come to novel conclusions about new information.\n",
    "- Simple example: \"The sun has risen every day I've been alive, so it will probably rise again tomorrow.\"\n",
    "  - Of course, there are limits to induction. One day the sun will almost certainly die out and not rise. But the fact that we can derive this useful heuristic for predicting the future based on past experience is an example of the utility of generalization.\n",
    "\n",
    "**In-Distribution:** When we train our models on data, the goal is to learn a distribution with maximizes the likelihood of the training data. So if data is in-distribution, it means that it was generated with the same function that generated the training samples.\n",
    "\n",
    "**Out-of-Distribution:** In contrast, data that was generated via a different function is considered out-of-distribution. And a model's ability to maintain it's predictive power on out-of-distribution tasks shows that the model is generalizing from whatever inductive heuristics it learned on it's training data.\n",
    "- Of course, there is a spectrum to how \"out\" of distribution we can get. Creative writing would clearly be out-of-distribution task for a model trained on simple addition. But our model failing to write short-stories wouldn't really tell us much since the task is *so* far OOD. But if we start giving it some significantly harder addition tasks than it was trained on, this suggests that the model has learned some fundamental representation of the nature of addition, and it's not simply memorizing and regurgitating the answers to questions it's already trained on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define a recursive function to generate an arithmetic expression and its evaluation chain-of-thought.\n",
    "def generate_expr(depth, operand_range):\n",
    "    \"\"\"\n",
    "    Recursively generate a fully parenthesized arithmetic expression along with:\n",
    "      - its evaluated numerical result\n",
    "      - a list of chain-of-thought (CoT) steps that show the intermediate computation.\n",
    "\n",
    "    Parameters:\n",
    "      depth (int): The recursion depth. A depth of 0 returns a single random number.\n",
    "      operand_range (tuple): A tuple (low, high) specifying the range from which to sample integers.\n",
    "    \n",
    "    Returns:\n",
    "      expr_str (str): The generated arithmetic expression as a string.\n",
    "      result (int): The evaluated result of the expression.\n",
    "      chain (list of str): A list of strings, each describing one computation step.\n",
    "    \"\"\"\n",
    "    # Base case: if depth is 0, return a random number within the operand_range.\n",
    "    if depth == 0:\n",
    "        num = random.randint(operand_range[0], operand_range[1])\n",
    "        # For a leaf, there's no computation step.\n",
    "        return str(num), num, []\n",
    "    \n",
    "    # Recursive case: generate a left and a right sub-expression.\n",
    "    left_expr, left_val, left_chain = generate_expr(depth - 1, operand_range)\n",
    "    right_expr, right_val, right_chain = generate_expr(depth - 1, operand_range)\n",
    "    \n",
    "    # Randomly choose an operator from the allowed list.\n",
    "    op = random.choice([\"+\", \"-\", \"*\"])\n",
    "    \n",
    "    # Form the new expression by fully parenthesizing the sub-expressions.\n",
    "    expr_str = f\"({left_expr} {op} {right_expr})\"\n",
    "    \n",
    "    # Compute the result based on the chosen operator.\n",
    "    if op == \"+\":\n",
    "        result = left_val + right_val\n",
    "    elif op == \"-\":\n",
    "        result = left_val - right_val\n",
    "    elif op == \"*\":\n",
    "        result = left_val * right_val\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported operator\")\n",
    "    \n",
    "    # Create a new chain-of-thought step for this operation.\n",
    "    # Note: We refer to the already computed numerical values for clarity.\n",
    "    new_step = f\"Compute {left_val} {op} {right_val} = {result}.\"\n",
    "    \n",
    "    # Combine the chain-of-thought from left and right sub-expressions with this new step.\n",
    "    # The order (left_chain, right_chain, then new_step) reflects a post-order (bottom-up) evaluation.\n",
    "    chain = left_chain + right_chain + [new_step]\n",
    "    \n",
    "    return expr_str, result, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Create a helper function to generate a dataset of examples.\n",
    "def generate_dataset(num_examples, depth_choices, operand_range, dataset_label):\n",
    "    \"\"\"\n",
    "    Generate a dataset of arithmetic expressions with chain-of-thought explanations.\n",
    "\n",
    "    Parameters:\n",
    "      num_examples (int): Number of examples to generate.\n",
    "      depth_choices (list): A list of possible depths to randomly choose from.\n",
    "      operand_range (tuple): A tuple (low, high) for sampling random numbers.\n",
    "      dataset_label (str): A label for the dataset (e.g., 'train', 'validation', 'OOD').\n",
    "\n",
    "    Returns:\n",
    "      df (pandas.DataFrame): A DataFrame containing the dataset with columns:\n",
    "          - 'dataset': the label (train, validation, or OOD)\n",
    "          - 'expression': the arithmetic expression as a string.\n",
    "          - 'chain_of_thought': the chain-of-thought as a list (or JSON string).\n",
    "          - 'answer': the computed numerical result.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i in range(num_examples):\n",
    "        # Randomly select a depth from the provided choices.\n",
    "        depth = random.choice(depth_choices)\n",
    "        expr, answer, chain = generate_expr(depth, operand_range)\n",
    "        # Save the example as a dictionary.\n",
    "        example = {\n",
    "            \"dataset\": dataset_label,\n",
    "            \"expression\": expr,\n",
    "            \"chain_of_thought\": json.dumps(chain),  # stored as a JSON string for readability\n",
    "            \"answer\": answer\n",
    "        }\n",
    "        data.append(example)\n",
    "    # Convert list of dictionaries into a pandas DataFrame.\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Examples:\n",
      "  dataset              expression  \\\n",
      "0   train               (20 + 17)   \n",
      "1   train  ((37 * 39) - (4 * 46))   \n",
      "2   train  ((19 * 38) * (5 - 35))   \n",
      "3   train               (39 * 30)   \n",
      "4   train  ((15 - 16) + (9 + 20))   \n",
      "\n",
      "                                    chain_of_thought  answer  \n",
      "0                          [\"Compute 20 + 17 = 37.\"]      37  \n",
      "1  [\"Compute 37 * 39 = 1443.\", \"Compute 4 * 46 = ...    1259  \n",
      "2  [\"Compute 19 * 38 = 722.\", \"Compute 5 - 35 = -...  -21660  \n",
      "3                        [\"Compute 39 * 30 = 1170.\"]    1170  \n",
      "4  [\"Compute 15 - 16 = -1.\", \"Compute 9 + 20 = 29...      28   \n",
      "\n",
      "Validation Set Examples:\n",
      "      dataset               expression  \\\n",
      "0  validation   ((8 * 24) + (22 - 12))   \n",
      "1  validation  ((25 - 10) - (21 - 47))   \n",
      "2  validation                  (2 * 4)   \n",
      "3  validation  ((38 - 18) - (11 * 30))   \n",
      "4  validation  ((45 * 39) - (36 - 14))   \n",
      "\n",
      "                                    chain_of_thought  answer  \n",
      "0  [\"Compute 8 * 24 = 192.\", \"Compute 22 - 12 = 1...     202  \n",
      "1  [\"Compute 25 - 10 = 15.\", \"Compute 21 - 47 = -...      41  \n",
      "2                             [\"Compute 2 * 4 = 8.\"]       8  \n",
      "3  [\"Compute 38 - 18 = 20.\", \"Compute 11 * 30 = 3...    -310  \n",
      "4  [\"Compute 45 * 39 = 1755.\", \"Compute 36 - 14 =...    1733   \n",
      "\n",
      "OOD Set Examples:\n",
      "  dataset                                         expression  \\\n",
      "0     OOD  (((109 - 300) + (426 * 393)) - ((333 - 115) - ...   \n",
      "1     OOD  (((320 + 428) - (103 + 225)) - ((475 * 437) * ...   \n",
      "2     OOD  (((487 * 331) + (403 - 377)) * ((240 + 266) * ...   \n",
      "3     OOD  (((149 * 440) + (272 - 111)) + ((229 - 105) + ...   \n",
      "4     OOD  (((235 - 371) * (416 * 321)) + ((492 + 277) + ...   \n",
      "\n",
      "                                    chain_of_thought         answer  \n",
      "0  [\"Compute 109 - 300 = -191.\", \"Compute 426 * 3...         213987  \n",
      "1  [\"Compute 320 + 428 = 748.\", \"Compute 103 + 22...        5812520  \n",
      "2  [\"Compute 487 * 331 = 161197.\", \"Compute 403 -...  2324670567648  \n",
      "3  [\"Compute 149 * 440 = 65560.\", \"Compute 272 - ...          66626  \n",
      "4  [\"Compute 235 - 371 = -136.\", \"Compute 416 * 3...      -18160300  \n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Generate the training, validation, and OOD test sets.\n",
    "# For training and validation, we use smaller numbers (e.g., 1 to 50) and lower expression depths.\n",
    "# For OOD, we use larger numbers (e.g., 100 to 500) and possibly higher depths to simulate harder problems.\n",
    "\n",
    "# Define dataset sizes and parameters.\n",
    "num_train = 2000        # Adjust as needed (e.g., between 1k-5k examples)\n",
    "num_validation = 300    # Typically 200-500 examples\n",
    "num_ood = 300           # Out-of-distribution set\n",
    "\n",
    "# For training and validation, use depth 1 or 2 (resulting in 1 or 2 operations).\n",
    "train_depth_choices = [1, 2]\n",
    "train_operand_range = (1, 50)  # smaller numbers\n",
    "\n",
    "# For OOD, use a higher depth (e.g., 3) and larger numbers.\n",
    "ood_depth_choices = [3]\n",
    "ood_operand_range = (100, 500)  # larger numbers to simulate OOD conditions\n",
    "\n",
    "# Generate the datasets.\n",
    "train_df = generate_dataset(num_train, train_depth_choices, train_operand_range, \"train\")\n",
    "validation_df = generate_dataset(num_validation, train_depth_choices, train_operand_range, \"validation\")\n",
    "ood_df = generate_dataset(num_ood, ood_depth_choices, ood_operand_range, \"OOD\")\n",
    "\n",
    "# For demonstration, display the first few rows of each dataset.\n",
    "print(\"Training Set Examples:\")\n",
    "print(train_df.head(), \"\\n\")\n",
    "\n",
    "print(\"Validation Set Examples:\")\n",
    "print(validation_df.head(), \"\\n\")\n",
    "\n",
    "print(\"OOD Set Examples:\")\n",
    "print(ood_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets have been saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: (Optional) Save the datasets to CSV files for later use.\n",
    "# You can adapt the file paths as needed.\n",
    "\n",
    "train_df.to_csv(\"countdown_train.csv\", index=False)\n",
    "validation_df.to_csv(\"countdown_validation.csv\", index=False)\n",
    "ood_df.to_csv(\"countdown_ood.csv\", index=False)\n",
    "\n",
    "print(\"Datasets have been saved to CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
